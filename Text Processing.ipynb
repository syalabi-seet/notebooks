{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bittfgpuconda4fd93528a0f64d8f95f013bcb74a441e",
   "display_name": "Python 3.7.9 64-bit ('tf-gpu': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re, nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "from scispacy.abbreviation import AbbreviationDetector\n",
    "from autocorrect import Speller\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet"
   ]
  },
  {
   "source": [
    "## Text pre-processing procedure\n",
    "1. Import raw text data\n",
    "2. Convert to lower casing\n",
    "3. Remove punctuations\n",
    "4. Expand abbreviations\n",
    "5. Perform tokenization\n",
    "6. Remove stop words\n",
    "7. Perform lemmatization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Performing Tokenization on Sample Text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          Text      Lemma PartofSpeech  Tag       Dep Shape is_alpha is_stop\n",
       "0           He     -PRON-         PRON  PRP     nsubj    Xx     True    True\n",
       "1         said        say         VERB  VBD      ROOT  xxxx     True   False\n",
       "2            ,          ,        PUNCT    ,     punct     ,    False   False\n",
       "3            \"          \"        PUNCT   ''     punct     \"    False   False\n",
       "4           we     -PRON-         PRON  PRP     nsubj    xx     True    True\n",
       "5           'd         'd         VERB   MD       aux    'x    False    True\n",
       "6         have       have          AUX   VB       aux  xxxx     True    True\n",
       "7        eaten        eat         VERB  VBN     ccomp  xxxx     True   False\n",
       "8         more       more          ADJ  JJR      amod  xxxx     True    True\n",
       "9         than       than        SCONJ   IN  quantmod  xxxx     True    True\n",
       "10         100        100          NUM   CD    nummod   ddd    False   False\n",
       "11  hamburgers  hamburger         NOUN  NNS      dobj  xxxx     True   False\n",
       "12        from       from          ADP   IN      prep  xxxx     True    True\n",
       "13   yesterday  yesterday         NOUN   NN      pobj  xxxx     True   False\n",
       "14           .          .        PUNCT    .     punct     .    False   False"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Lemma</th>\n      <th>PartofSpeech</th>\n      <th>Tag</th>\n      <th>Dep</th>\n      <th>Shape</th>\n      <th>is_alpha</th>\n      <th>is_stop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>He</td>\n      <td>-PRON-</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>nsubj</td>\n      <td>Xx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>said</td>\n      <td>say</td>\n      <td>VERB</td>\n      <td>VBD</td>\n      <td>ROOT</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,</td>\n      <td>,</td>\n      <td>PUNCT</td>\n      <td>,</td>\n      <td>punct</td>\n      <td>,</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"</td>\n      <td>\"</td>\n      <td>PUNCT</td>\n      <td>''</td>\n      <td>punct</td>\n      <td>\"</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>we</td>\n      <td>-PRON-</td>\n      <td>PRON</td>\n      <td>PRP</td>\n      <td>nsubj</td>\n      <td>xx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>'d</td>\n      <td>'d</td>\n      <td>VERB</td>\n      <td>MD</td>\n      <td>aux</td>\n      <td>'x</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>have</td>\n      <td>have</td>\n      <td>AUX</td>\n      <td>VB</td>\n      <td>aux</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>eaten</td>\n      <td>eat</td>\n      <td>VERB</td>\n      <td>VBN</td>\n      <td>ccomp</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>more</td>\n      <td>more</td>\n      <td>ADJ</td>\n      <td>JJR</td>\n      <td>amod</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>than</td>\n      <td>than</td>\n      <td>SCONJ</td>\n      <td>IN</td>\n      <td>quantmod</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100</td>\n      <td>100</td>\n      <td>NUM</td>\n      <td>CD</td>\n      <td>nummod</td>\n      <td>ddd</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>hamburgers</td>\n      <td>hamburger</td>\n      <td>NOUN</td>\n      <td>NNS</td>\n      <td>dobj</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>from</td>\n      <td>from</td>\n      <td>ADP</td>\n      <td>IN</td>\n      <td>prep</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>yesterday</td>\n      <td>yesterday</td>\n      <td>NOUN</td>\n      <td>NN</td>\n      <td>pobj</td>\n      <td>xxxx</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>.</td>\n      <td>.</td>\n      <td>PUNCT</td>\n      <td>.</td>\n      <td>punct</td>\n      <td>.</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = 'He said, \"we\\'d have eaten more than 100 hamburgers from yesterday.\"'\n",
    "\n",
    "token_sentence = nlp(text)\n",
    "\n",
    "token_dict = {}\n",
    "for token in token_sentence:\n",
    "    token_dict[token.text] = [token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop]\n",
    "\n",
    "pd.DataFrame(token_dict).T.reset_index().rename(columns={'index': 'Text', \n",
    "                                                         0: 'Lemma',\n",
    "                                                         1: 'PartofSpeech', \n",
    "                                                         2: 'Tag',\n",
    "                                                         3: 'Dep',\n",
    "                                                         4: 'Shape',\n",
    "                                                         5: 'is_alpha',\n",
    "                                                         6: 'is_stop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['say', '100', 'yesterday', 'eat', 'hamburger']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "abbreviation_pipe = AbbreviationDetector(nlp)\n",
    "nlp.add_pipe(abbreviation_pipe)\n",
    "\n",
    "def preprocess_token(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    def is_token_allowed(token):\n",
    "        if (not token or not token.string.strip() or token.is_stop or token.is_punct):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    for abrv in doc._.abbreviations:\n",
    "        tokens[abrv.start] = str(abrv._.long_form)\n",
    "\n",
    "    doc = nlp(' '.join(tokens))\n",
    "            \n",
    "    tokens = set([token.lemma_.strip().lower() for token in doc if is_token_allowed(token)])\n",
    "\n",
    "    return list(tokens)\n",
    "\n",
    "preprocessed_tokens = preprocess_token(text)\n",
    "preprocessed_tokens"
   ]
  },
  {
   "source": [
    "## Import and print Text data file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 Hello\n1 Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n2 What is definition of Autistic Spectrum Disorder?\n3 Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n4 What are the symptoms of Autistic Spectrum Disorder?\n5 Making little or inconsistent eye contact. \n6 Tending not to look at or listen to people.\n7 Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n8 Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n9 Having difficulties with the back and forth of conversation.\n10 Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n11 Having facial expressions, movements, and gestures that do not match what is being said.\n12 Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n13 Having trouble understanding another person’s point of view or being unable to predict or understand other people’s actions.\n14 Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n15 Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n16 Having overly focused interests, such as with moving objects or parts of objects.\n17 Getting upset by slight changes in a routine.\n18 Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n19 People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n20 Being able to learn things in detail and remember information for long periods of time.\n21 Being strong visual and auditory learners.\n22 Excelling in math, science, music, or art.\n23 What should I do if I got diagnosis the Autistic Spectrum Disorder?\n24 Consult a doctor and psychologist for early intervention programs.\n"
     ]
    }
   ],
   "source": [
    "with open('E:\\School stuff/1.3.2 workshop/1.3.2 workshop/questionbase_raw.txt', encoding='UTF-8') as file:\n",
    "    raw_sentences = [sentence.replace('\\n', '') for sentence in file.readlines()]\n",
    "\n",
    "# Drop\n",
    "for raw_sentence in raw_sentences:\n",
    "    if (raw_sentence == 'Q') or (raw_sentence == 'A'):\n",
    "        raw_sentences.remove(raw_sentence)\n",
    "\n",
    "for i, raw_sentence in enumerate(raw_sentences):\n",
    "    print(i, raw_sentence)"
   ]
  },
  {
   "source": [
    "## Provided processing wrapper functions\n",
    "\n",
    "We used autocorrect.Speller library to form the spell_checker function.\n",
    "\n",
    "#### Quiz: How to implement this function without using str.lower()?\n",
    "We can implement str.casefold() instead of str.lower()."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_casing(sentence):\n",
    "    new_sentence = sentence.lower()\n",
    "    return new_sentence\n",
    "\n",
    "def expand_abbriviation(sentence):\n",
    "    replacement_patterns = [\n",
    "        (r'won\\'t', 'will not'),\n",
    "        (r'can\\'t', 'cannot'),\n",
    "        (r'i\\'m', 'i am'),\n",
    "        (r'ain\\'t', 'is not'),\n",
    "        (r'(\\w+)\\'ll', '\\g<1> will'),\n",
    "        (r'(\\w+)n\\'t', '\\g<1> not'),\n",
    "        (r'(\\w+)\\'ve', '\\g<1> have'),\n",
    "        (r'(\\w+)\\'s', '\\g<1> is'),\n",
    "        (r'(\\w+)\\'re', '\\g<1> are'),\n",
    "        (r'(\\w+)\\'d', '\\g<1> would')]\n",
    "    patterns = [(re.compile(regex), repl) for (regex, repl) in replacement_patterns]\n",
    "\n",
    "    new_sentence = sentence\n",
    "    for (pattern, repl) in patterns:\n",
    "        (new_sentence, count) = re.subn(pattern, repl, new_sentence)\n",
    "    return new_sentence\n",
    "\n",
    "def punctuation_removal(sentence):\n",
    "    # Remove the all the punctuations except '\n",
    "    new_sentence = re.sub(',|!|\\?|\\\"|<|>|\\(|\\)|\\[|\\]|\\{|\\}|@|#|\\+|\\=|\\-|\\_|~|\\&|\\*|\\^|%|\\||\\$|/|`|\\.|\\'',\n",
    "                          '', sentence,count=0, flags=0)\n",
    "    return new_sentence\n",
    "\n",
    "def tokenization(sentence):\n",
    "    new_sentence = nltk.word_tokenize(sentence)\n",
    "    return new_sentence\n",
    "\n",
    "def stopword_removal(sentence):\n",
    "    stoplist = stopwords.words('english')\n",
    "     \n",
    "    with open(r'E:\\School stuff\\1.3.2 workshop\\1.3.2 workshop/stopwords.txt') as file:\n",
    "        stoplist = [stopword.replace('\\n', '').lower() for stopword in file.readlines()]\n",
    "    \n",
    "    new_sentence = [word for word in sentence if word not in stoplist]\n",
    "    return new_sentence\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    pack = nltk.pos_tag([word])\n",
    "    tag = pack[0][1]\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatization(sentence):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    new_sentence = [lemmatizer.lemmatize(word, get_wordnet_pos(word) or wordnet.NOUN) for word in sentence]\n",
    "\n",
    "    return new_sentence\n",
    "\n",
    "def spell_checker(sentence):\n",
    "    spell = Speller(lang='en')\n",
    "\n",
    "    new_sentence = spell(sentence)\n",
    "\n",
    "    return new_sentence\n",
    "\n",
    "def text_preprocessing(raw_sentence):\n",
    "    sentence = lower_casing(raw_sentence)\n",
    "    sentence = spell_checker(sentence)\n",
    "    sentence = punctuation_removal(sentence)\n",
    "    sentence = expand_abbriviation(sentence)\n",
    "    sentence = tokenization(sentence)\n",
    "    sentence = stopword_removal(sentence)\n",
    "    sentence = lemmatization(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence 1\n",
      "Original Sentence: Hello\n",
      "Own processing: ['hello']\n",
      "Provided processing: []\n",
      "\n",
      "Sentence 2\n",
      "Original Sentence: Hello, I am ASD knowledge bot. Feel free to ask me anything about autism spectrum disorder (ASD).\n",
      "Own processing: ['ask', 'autism', 'bot', 'disorder', 'feel', 'free', 'hello', 'knowledge', 'spectrum']\n",
      "Provided processing: ['asd', 'asd', 'autism', 'bot', 'disorder', 'feel', 'free', 'knowledge', 'spectrum']\n",
      "\n",
      "Sentence 3\n",
      "Original Sentence: What is definition of Autistic Spectrum Disorder?\n",
      "Own processing: ['autistic', 'definition', 'disorder', 'spectrum']\n",
      "Provided processing: ['autistic', 'definition', 'disorder', 'spectrum']\n",
      "\n",
      "Sentence 4\n",
      "Original Sentence: Autism, or autism spectrum disorder (ASD), refers to a broad range of conditions characterized by challenges with social skills, repetitive behaviors, speech and nonverbal communication. According to the Centers for Disease Control, autism affects an estimated 1 in 54 children in the United States today.\n",
      "Own processing: ['1', '54', 'accord', 'affect', 'autism', 'behavior', 'broad', 'centers', 'challenge', 'characterize', 'child', 'communication', 'condition', 'control', 'disease', 'disorder', 'estimate', 'nonverbal', 'range', 'refer', 'repetitive', 'skill', 'social', 'spectrum', 'speech', 'states', 'today', 'united']\n",
      "Provided processing: ['1', '54', 'asd', 'autism', 'autism', 'autism', 'behavior', 'broad', 'center', 'challenge', 'characterize', 'child', 'communication', 'condition', 'control', 'disease', 'disorder', 'estimate', 'nonverbal', 'range', 'refers', 'repetitive', 'skill', 'social', 'spectrum', 'speech', 'united']\n",
      "\n",
      "Sentence 5\n",
      "Original Sentence: What are the symptoms of Autistic Spectrum Disorder?\n",
      "Own processing: ['autistic', 'disorder', 'spectrum', 'symptom']\n",
      "Provided processing: ['autistic', 'disorder', 'spectrum', 'symptom']\n",
      "\n",
      "Sentence 6\n",
      "Original Sentence: Making little or inconsistent eye contact. \n",
      "Own processing: ['contact', 'eye', 'inconsistent', 'little', 'make']\n",
      "Provided processing: ['contact', 'eye', 'inconsistent']\n",
      "\n",
      "Sentence 7\n",
      "Original Sentence: Tending not to look at or listen to people.\n",
      "Own processing: ['listen', 'look', 'people', 'tend']\n",
      "Provided processing: ['listen', 'not', 'people', 'tend']\n",
      "\n",
      "Sentence 8\n",
      "Original Sentence: Rarely sharing enjoyment of objects or activities by pointing or showing things to others.\n",
      "Own processing: ['activity', 'enjoyment', 'object', 'point', 'rarely', 'share', 'show', 'thing']\n",
      "Provided processing: ['activity', 'enjoyment', 'object', 'rarely', 'share']\n",
      "\n",
      "Sentence 9\n",
      "Original Sentence: Failing to, or being slow to, respond to someone calling their name or to other verbal attempts to gain attention.\n",
      "Own processing: ['attempt', 'attention', 'call', 'fail', 'gain', 'respond', 'slow', 'verbal']\n",
      "Provided processing: ['attempt', 'attention', 'call', 'fail', 'gain', 'respond', 'slow', 'verbal']\n",
      "\n",
      "Sentence 10\n",
      "Original Sentence: Having difficulties with the back and forth of conversation.\n",
      "Own processing: ['conversation', 'difficulty', 'forth', 'have']\n",
      "Provided processing: ['conversation', 'difficulty']\n",
      "\n",
      "Sentence 11\n",
      "Original Sentence: Often talking at length about a favorite subject without noticing that others are not interested or without giving others a chance to respond.\n",
      "Own processing: ['chance', 'favorite', 'give', 'interested', 'length', 'notice', 'respond', 'subject', 'talk']\n",
      "Provided processing: ['chance', 'favorite', 'length', 'not', 'notice', 'respond', 'subject', 'talk']\n",
      "\n",
      "Sentence 12\n",
      "Original Sentence: Having facial expressions, movements, and gestures that do not match what is being said.\n",
      "Own processing: ['expression', 'facial', 'gesture', 'have', 'match', 'movement', 'say']\n",
      "Provided processing: ['expression', 'facial', 'gesture', 'match', 'movement', 'not']\n",
      "\n",
      "Sentence 13\n",
      "Original Sentence: Having an unusual tone of voice that may sound sing-song or flat and robot-like.\n",
      "Own processing: ['flat', 'have', 'like', 'robot', 'sing', 'song', 'sound', 'tone', 'unusual', 'voice']\n",
      "Provided processing: ['flat', 'robotlike', 'singsong', 'sound', 'tone', 'unusual', 'voice']\n",
      "\n",
      "Sentence 14\n",
      "Original Sentence: Having trouble understanding another person’s point of view or being unable to predict or understand other people’s actions.\n",
      "Own processing: ['action', 'have', 'people', 'person', 'point', 'predict', 'trouble', 'unable', 'understand', 'view']\n",
      "Provided processing: ['action', 'people', 'person', 'predict', 'trouble', 'unable', 'understand', 'understand', 'view', '’', '’']\n",
      "\n",
      "Sentence 15\n",
      "Original Sentence: Repeating certain behaviors or having unusual behaviors. For example, repeating words or phrases, a behavior called echolalia.\n",
      "Own processing: ['behavior', 'call', 'certain', 'echolalia', 'example', 'have', 'phrase', 'repeat', 'unusual', 'word']\n",
      "Provided processing: ['behavior', 'behavior', 'behavior', 'call', 'echolalia', 'phrase', 'repeat', 'repeat', 'unusual']\n",
      "\n",
      "Sentence 16\n",
      "Original Sentence: Having a lasting intense interest in certain topics, such as numbers, details, or facts.\n",
      "Own processing: ['certain', 'detail', 'fact', 'have', 'intense', 'interest', 'last', 'number', 'topic']\n",
      "Provided processing: ['detail', 'intense', 'last', 'topic']\n",
      "\n",
      "Sentence 17\n",
      "Original Sentence: Having overly focused interests, such as with moving objects or parts of objects.\n",
      "Own processing: ['focus', 'have', 'interest', 'move', 'object', 'overly', 'part']\n",
      "Provided processing: ['focus', 'move', 'object', 'object', 'overly']\n",
      "\n",
      "Sentence 18\n",
      "Original Sentence: Getting upset by slight changes in a routine.\n",
      "Own processing: ['change', 'get', 'routine', 'slight', 'upset']\n",
      "Provided processing: ['routine', 'slight', 'upset']\n",
      "\n",
      "Sentence 19\n",
      "Original Sentence: Being more or less sensitive than other people to sensory input, such as light, noise, clothing, or temperature.\n",
      "Own processing: ['clothing', 'input', 'light', 'noise', 'people', 'sensitive', 'sensory', 'temperature']\n",
      "Provided processing: ['clothing', 'input', 'light', 'noise', 'people', 'sensitive', 'sensory', 'temperature']\n",
      "\n",
      "Sentence 20\n",
      "Original Sentence: People with ASD may also experience sleep problems and irritability. Although people with ASD experience many challenges, they may also have many strengths, including:\n",
      "Own processing: ['asd', 'challenge', 'experience', 'include', 'irritability', 'people', 'problem', 'sleep', 'strength']\n",
      "Provided processing: [':', 'asd', 'asd', 'challenge', 'experience', 'experience', 'include', 'irritability', 'people', 'people', 'sleep', 'strength']\n",
      "\n",
      "Sentence 21\n",
      "Original Sentence: Being able to learn things in detail and remember information for long periods of time.\n",
      "Own processing: ['able', 'detail', 'information', 'learn', 'long', 'period', 'remember', 'thing', 'time']\n",
      "Provided processing: ['detail', 'learn', 'period', 'remember', 'time']\n",
      "\n",
      "Sentence 22\n",
      "Original Sentence: Being strong visual and auditory learners.\n",
      "Own processing: ['auditory', 'learner', 'strong', 'visual']\n",
      "Provided processing: ['auditory', 'learner', 'strong', 'visual']\n",
      "\n",
      "Sentence 23\n",
      "Original Sentence: Excelling in math, science, music, or art.\n",
      "Own processing: ['art', 'excel', 'math', 'music', 'science']\n",
      "Provided processing: ['art', 'expel', 'math', 'music', 'science']\n",
      "\n",
      "Sentence 24\n",
      "Original Sentence: What should I do if I got diagnosis the Autistic Spectrum Disorder?\n",
      "Own processing: ['autistic', 'diagnosis', 'disorder', 'get', 'spectrum']\n",
      "Provided processing: ['autistic', 'diagnosis', 'disorder', 'spectrum']\n",
      "\n",
      "Sentence 25\n",
      "Original Sentence: Consult a doctor and psychologist for early intervention programs.\n",
      "Own processing: ['consult', 'doctor', 'early', 'intervention', 'program', 'psychologist']\n",
      "Provided processing: ['consult', 'doctor', 'intervention', 'program', 'psychologist']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for raw_sentence in raw_sentences:\n",
    "    processed_spacy = preprocess_token(raw_sentence)\n",
    "    processed_custom = text_preprocessing(raw_sentence)\n",
    "    if raw_sentence != 'Q' and raw_sentence != 'A':\n",
    "        print('Sentence', i)\n",
    "        print('Original Sentence:', raw_sentence)\n",
    "        print('Own processing:', sorted(processed_spacy))\n",
    "        print('Provided processing:', sorted(processed_custom))\n",
    "        i += 1\n",
    "        print()"
   ]
  },
  {
   "source": [
    "## Conclusion\n",
    "\n",
    "Comparing both preprocessing functions, they are slightly different in some aspects like;\n",
    "\n",
    "1. SpaCy's stop word library is slightly different compared to NLTK stop word library that was used in the provided preprocessing functions. Some words were omitted in provided preprocessing function but was not removed in SpaCy '.is_stop' tokenization function.\n",
    "2. Duplicates were not removed in the provided preprocessing functions.\n",
    "3. Provided preprocessing function was lengthy but customizable.\n",
    "4. Some punctuations were still present after the provided preprocessing function.\n",
    "5. Some abbreviations like 'ASD' were not expanded in the provided preprocessing function.\n",
    "\n",
    "In conclusion, SpaCy's implementation was more efficient but an integrated implementation between SpaCy and NLTK libraries could be more efficient and accurate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}